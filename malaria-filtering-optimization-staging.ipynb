{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b896f",
   "metadata": {
    "code_folding": [
     177,
     213
    ],
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-07 05:43:27,045] A new study created in memory with name: no-name-bc859036-861f-4e7e-a6d7-972d441005ba\n",
      "[I 2024-05-07 05:56:58,154] Trial 0 finished with value: 0.9798681333060042 and parameters: {'n_estimators': 73, 'max_features': 4, 'contamination': 0.0764158410101489}. Best is trial 0 with value: 0.9798681333060042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted SNP SCORE ROC_AUC: 0.9798681333060042\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from google.cloud import storage\n",
    "from google.cloud.storage.blob import Blob\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import firecloud.api as fapi\n",
    "import pickle\n",
    "from io import StringIO\n",
    "\n",
    "# Google Cloud and Terra setup\n",
    "PROJECT_ID = '1091079109155' \n",
    "BUCKET_NAME = 'fc-0c540a8a-11ec-4cf7-b7ff-39de06b1bca3'\n",
    "billing_project = 'broad-firecloud-dsde-methods'\n",
    "workspace = 'malaria-filtering-optimization-staging_monica'\n",
    "cnamespace = 'malaria-filtering-optimization-staging'\n",
    "configname = 'FilterAndEvaluate'\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "\n",
    "def get_hyperparameters_path_from_config():\n",
    "    \"\"\"Retrieve the hyperparameters JSON path from the workspace configuration.\"\"\"\n",
    "    config = fapi.get_workspace_config(billing_project, workspace, cnamespace, configname).json()\n",
    "    hyperparameters_json_path = config['inputs']['FilterAndEvaluate.JointVcfFiltering.hyperparameters_json']\n",
    "    return hyperparameters_json_path.strip('\\\"')  # Remove extra quotes\n",
    "\n",
    "def update_and_upload_hyperparameters(trial, config_path):\n",
    "    # Parse the bucket name and the path inside the bucket from the config path\n",
    "    bucket_name, base_path = config_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    directory_path, json_filename = os.path.split(base_path)\n",
    "    \n",
    "    # Extract the base model name from the file name without the extension\n",
    "    # Assume the base model name does not contain underscores followed by 'trial'\n",
    "    base_model_name = json_filename.split('_trial_')[0]\n",
    "    base_model_name, _ = os.path.splitext(base_model_name)\n",
    "    \n",
    "    # Create a trial-specific JSON filename\n",
    "    trial_specific_filename = f\"{base_model_name}_trial_{trial.number}.json\"\n",
    "    trial_specific_path = os.path.join(directory_path, trial_specific_filename)\n",
    "\n",
    "    # Initialize Google Cloud Storage bucket and blob\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Check if the original hyperparameters JSON file exists and load it\n",
    "    original_blob = bucket.blob(base_path)\n",
    "    if not original_blob.exists():\n",
    "        raise FileNotFoundError(f\"The hyperparameters file does not exist at the path '{config_path}'\")\n",
    "    config = json.loads(original_blob.download_as_text())\n",
    "\n",
    "    # Update config with new trial data\n",
    "    new_updated_values = {}\n",
    "    search_space = config.get('search_space', {})\n",
    "    for param, specs in search_space.items():\n",
    "        if specs['type'] == 'int':\n",
    "            new_updated_values[param] = trial.suggest_int(param, specs['low'], specs['high'])\n",
    "        elif specs['type'] == 'float':\n",
    "            new_updated_values[param] = trial.suggest_float(param, specs['low'], specs['high'])\n",
    "        elif specs['type'] == 'categorical':\n",
    "            new_updated_values[param] = trial.suggest_categorical(param, specs['options'])\n",
    "\n",
    "    config['updated_values'] = new_updated_values\n",
    "\n",
    "    # Save updated JSON in the directory specified by the original config path\n",
    "    updated_blob = bucket.blob(trial_specific_path)\n",
    "    updated_blob.upload_from_string(json.dumps(config), content_type='application/json')\n",
    "\n",
    "    return f\"gs://{bucket_name}/{trial_specific_path}\"\n",
    "\n",
    "\n",
    "\n",
    "def submit_trial_workflow(trial, updated_hyperparameters_path):\n",
    "    # Retrieve current workspace configuration\n",
    "    workspace_config = fapi.get_workspace_config(billing_project, workspace, cnamespace, configname).json()\n",
    "\n",
    "    # Update the hyperparameters JSON path in the workspace configuration\n",
    "    workspace_config['inputs']['FilterAndEvaluate.JointVcfFiltering.hyperparameters_json'] = f'\"{updated_hyperparameters_path}\"'\n",
    "\n",
    "    # Update the workspace configuration with the new hyperparameters JSON path\n",
    "    update_response = fapi.update_workspace_config(billing_project, workspace, cnamespace, configname,\n",
    "        body=workspace_config)\n",
    "    if update_response.status_code != 200:\n",
    "        raise Exception(f\"Failed to update workspace config: {update_response.text}\")\n",
    "\n",
    "    # Submit the workflow with the updated configuration\n",
    "    submission_response = fapi.create_submission(billing_project, workspace, cnamespace, configname)\n",
    "    if submission_response.status_code == 201:\n",
    "        submission_id = submission_response.json()['submissionId']\n",
    "        return submission_id\n",
    "    else:\n",
    "        raise Exception(f\"Failed to submit workflow: {submission_response.text}\")\n",
    "\n",
    "\n",
    "def wait_for_workflow_completion(submission_id):\n",
    "    while True:\n",
    "        submission_status = fapi.get_submission(billing_project, workspace, submission_id).json()\n",
    "        if submission_status['status'] in ['Done', 'Aborted']:\n",
    "            workflow_id = submission_status['workflows'][0]['workflowId']\n",
    "            return workflow_id\n",
    "        time.sleep(60)\n",
    "\n",
    "def fetch_process_and_extract_scores(billing_project, workspace, submission_id, workflow_id):\n",
    "    # Fetch workflow outputs to get the metrics TSV file path\n",
    "    outputs_response = fapi.get_workflow_outputs(billing_project, workspace, submission_id, workflow_id)\n",
    "    if outputs_response.status_code != 200:\n",
    "        print(\"Failed to get workflow outputs\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Extract the metrics file path from the response\n",
    "        metrics_file_path = outputs_response.json()['tasks']['FilterAndEvaluate']['outputs']['FilterAndEvaluate.metrics_pkl']\n",
    "        bucket_name, blob_path = metrics_file_path.replace('gs://', '').split('/', 1)\n",
    "    except KeyError:\n",
    "        print(\"Metrics file path not found in workflow outputs.\")\n",
    "        return None\n",
    "\n",
    "    # Download and load the pickle file\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_path)\n",
    "    score_data = pickle.loads(blob.download_as_bytes())\n",
    "\n",
    "    # Process the loaded score data to extract the required scores\n",
    "    try:\n",
    "        snp_score_roc_auc = score_data['SCORE']['snp']['ROC_AUC']\n",
    "        print(\"Extracted SNP SCORE ROC_AUC:\", snp_score_roc_auc)\n",
    "        return snp_score_roc_auc  # Returning ROC_AUC for SNP for hyperparameter tuning\n",
    "    except KeyError:\n",
    "        print(\"Required score data not found in the pickle file.\")\n",
    "        return None\n",
    "\n",
    "def save_trial_outputs(trial_number, submission_id, workflow_id):\n",
    "    outputs_response = fapi.get_workflow_outputs(billing_project, workspace, submission_id, workflow_id)\n",
    "    if outputs_response.status_code != 200:\n",
    "        raise Exception(\"Failed to get workflow outputs\")\n",
    "\n",
    "    # The base path where trial-specific outputs will be saved\n",
    "    base_path = f\"trial_{trial_number}\"\n",
    "\n",
    "    # Retrieve the outputs from the response\n",
    "    outputs = outputs_response.json()['tasks']['FilterAndEvaluate']['outputs']\n",
    "\n",
    "    # Access the bucket\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "    # Process each output file\n",
    "    for output_type, file_paths in outputs.items():\n",
    "        if not isinstance(file_paths, list):\n",
    "            file_paths = [file_paths]\n",
    "        for file_path in file_paths:\n",
    "            # Extract the filename and create a trial-specific path\n",
    "            _, file_name = os.path.split(file_path.replace('gs://', ''))\n",
    "            trial_specific_path = os.path.join(base_path, file_name)\n",
    "            \n",
    "            # Copy the file to the trial-specific path\n",
    "            source_blob = bucket.blob(file_path.replace(f\"gs://{BUCKET_NAME}/\", \"\"))\n",
    "            new_blob = bucket.copy_blob(source_blob, bucket, trial_specific_path)\n",
    "            #print(f\"Copied {file_path} to {new_blob.public_url}\")\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        config_path = get_hyperparameters_path_from_config()\n",
    "        updated_hyperparameters_path = update_and_upload_hyperparameters(trial, config_path)\n",
    "        \n",
    "        submission_id = submit_trial_workflow(trial, updated_hyperparameters_path)\n",
    "        workflow_id = wait_for_workflow_completion(submission_id)\n",
    "        \n",
    "        # Store the submission ID in trial's user attributes and return the score\n",
    "        trial.set_user_attr(\"submission_id\", submission_id)\n",
    "        \n",
    "        score = fetch_process_and_extract_scores(billing_project, workspace, submission_id, workflow_id)\n",
    "        return score if score is not None else float('-inf')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during trial {trial.number}: {str(e)}\")\n",
    "        return float('-inf')\n",
    "\n",
    "def run_optimization():\n",
    "    try:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=2)  # Adjust the number of trials as necessary\n",
    "        best_trial = max((trial for trial in study.trials if trial.value != float('-inf')),\n",
    "                         key=lambda t: t.value, default=None)\n",
    "        \n",
    "        if best_trial:\n",
    "            print(f\"Best successful trial: {best_trial.number}\")\n",
    "            print(f\"Best value: {best_trial.value}\")\n",
    "            for key, value in best_trial.params.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "                \n",
    "            # Retrieve the hyperparameters path used in the best trial\n",
    "            best_hyperparameters_path = update_and_upload_hyperparameters(best_trial, get_hyperparameters_path_from_config())\n",
    "            \n",
    "            # Execute the test phase only once with these best hyperparameters and specific test settings\n",
    "            test_scores = test_phase(best_hyperparameters_path)\n",
    "\n",
    "            if test_scores:\n",
    "                print(\"Test scores have been successfully extracted and processed.\")\n",
    "            else:\n",
    "                print(\"Unable to extract or process test scores.\")\n",
    "        else:\n",
    "            print(\"No successful trials were completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the optimization or test phase: {e}\")\n",
    "\n",
    "\n",
    "def test_phase(updated_hyperparameters_path):\n",
    "    workspace_config = fapi.get_workspace_config(billing_project, workspace, cnamespace, configname).json()\n",
    "    \n",
    "    # Update the workspace configuration specifically for testing\n",
    "    workspace_config['inputs']['FilterAndEvaluate.JointVcfFiltering.hyperparameters_json'] = f'\"{updated_hyperparameters_path}\"'\n",
    "    workspace_config['inputs']['FilterAndEvaluate.JointVcfFiltering.score_extra_args'] = \"\\\"--ignore-all-filters -L Pf3D7_03_v3 --resource-matching-strategy START_POSITION_AND_MINIMAL_REPRESENTATION\\\"\"\n",
    "    \n",
    "    update_response = fapi.update_workspace_config(billing_project, workspace, cnamespace, configname, workspace_config)\n",
    "    if update_response.status_code != 200:\n",
    "        raise Exception(f\"Failed to update workspace config for testing: {update_response.text}\")\n",
    "    \n",
    "    submission_response = fapi.create_submission(billing_project, workspace, cnamespace, configname)\n",
    "    if submission_response.status_code != 201:\n",
    "        raise Exception(f\"Failed to submit test workflow: {submission_response.text}\")\n",
    "    \n",
    "    submission_id = submission_response.json()['submissionId']\n",
    "    print(f\"Test workflow submitted successfully. Submission ID: {submission_id}\")\n",
    "    \n",
    "    workflow_id = wait_for_workflow_completion(submission_id)\n",
    "    print(f\"Test workflow completed. Workflow ID: {workflow_id}\")\n",
    "    \n",
    "    test_scores = fetch_process_and_extract_scores(billing_project, workspace, submission_id, workflow_id)\n",
    "    if test_scores:\n",
    "        print(f\"Extracted test phase scores: {test_scores}\")\n",
    "    else:\n",
    "        print(\"Failed to extract scores from the test phase.\")\n",
    "    return test_scores\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_optimization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
